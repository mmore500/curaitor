{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T09:58:15.579407Z",
     "iopub.status.busy": "2024-06-28T09:58:15.579239Z",
     "iopub.status.idle": "2024-06-28T09:58:16.747853Z",
     "shell.execute_reply": "2024-06-28T09:58:16.747303Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"articles/review\", exist_ok=True)\n",
    "\n",
    "from script.cropPage import *\n",
    "from script.textMining import *\n",
    "from script.textSegments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T09:58:16.750547Z",
     "iopub.status.busy": "2024-06-28T09:58:16.750049Z",
     "iopub.status.idle": "2024-06-28T09:58:46.584341Z",
     "shell.execute_reply": "2024-06-28T09:58:46.583757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "ollama.pull(\"llama3\")\n",
    "ollama.pull(\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T09:58:46.586839Z",
     "iopub.status.busy": "2024-06-28T09:58:46.586332Z",
     "iopub.status.idle": "2024-06-28T09:58:48.311902Z",
     "shell.execute_reply": "2024-06-28T09:58:48.311277Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://vuir.vu.edu.au/43558/1/Ep43558.pdf\"\n",
    "\n",
    "# Extract filename and append '.pdf'\n",
    "filename = url.split(\"/\")[-1]\n",
    "\n",
    "# Full path where the file will be saved\n",
    "path = os.path.join(\"articles\", filename)\n",
    "\n",
    "# Send a GET request to the URL with headers\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "# Save the file if the request was successful\n",
    "assert response.status_code == 200, response.status_code\n",
    "\n",
    "with open(path, \"wb\") as f:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Crop page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T09:58:48.314392Z",
     "iopub.status.busy": "2024-06-28T09:58:48.314094Z",
     "iopub.status.idle": "2024-06-28T09:58:49.282600Z",
     "shell.execute_reply": "2024-06-28T09:58:49.282008Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing files:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles/Ep43558.pdf\n",
      "document has 20 pages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing files (Processed: 1/2):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing files (Processed: 1/2):  50%|█████     | 1/2 [00:00<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing files (Processed: 2/2):  50%|█████     | 1/2 [00:00<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing files (Processed: 3/2): 100%|██████████| 2/2 [00:00<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing files (Processed: 3/2): : 3it [00:00,  3.50it/s]                     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory containing PDFs to process\n",
    "pdfsDirectory = \"articles\"\n",
    "totalFiles = len(os.listdir(pdfsDirectory))\n",
    "\n",
    "# Output directory for cleaned text files\n",
    "outputDirectory = os.path.join(pdfsDirectory, \"output\")\n",
    "\n",
    "# Crop all PDFs in the directory\n",
    "cropAllPdfs(pdfsDirectory, outputDirectory, totalFiles)\n",
    "\n",
    "# Test single PDF\n",
    "# pdfPath= \"review/1-s2.0-S0143416016300094-main.pdf\"\n",
    "# cropPDFMargins(pdfPath, outputDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Extract text\n",
    "\n",
    "Table not working yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T09:58:49.285023Z",
     "iopub.status.busy": "2024-06-28T09:58:49.284675Z",
     "iopub.status.idle": "2024-06-28T09:58:50.632172Z",
     "shell.execute_reply": "2024-06-28T09:58:50.631576Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Mining PDFs:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep43558_cropped.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Mining PDFs: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Mining PDFs: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text has been written to file: articles/output/textOutput/Ep43558_cropped_output_text.txt\n",
      "Cleaning Ep43558_cropped_output_text.txt...\n",
      "Ep43558_cropped_output_text.txt has been cleaned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory containing your text files\n",
    "text_files_directory = \"articles/output/textOutput\"\n",
    "\n",
    "# Directory containing PDFs to process\n",
    "pdfs_directory = \"articles/output\"\n",
    "\n",
    "# Output directory for cleaned text files\n",
    "output_directory = os.path.join(pdfs_directory, \"textOutput\")\n",
    "\n",
    "# Process all PDFs in the directory\n",
    "process_all_pdfs(pdfs_directory, output_directory)\n",
    "process_text_files(text_files_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Text segment\n",
    "\n",
    "Get embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T09:58:50.634499Z",
     "iopub.status.busy": "2024-06-28T09:58:50.634176Z",
     "iopub.status.idle": "2024-06-28T09:59:48.021026Z",
     "shell.execute_reply": "2024-06-28T09:59:48.020403Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing files:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing files: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing files: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# List of PDF file names\n",
    "txt_directory = \"articles/output/textOutput\"\n",
    "output_text_directory = \"text_output\"\n",
    "# Configure OpenAI API key\n",
    "key_file_path = \"api_key\"\n",
    "\n",
    "if \"OPENAI_API_KEY\" in os.environ:\n",
    "    with open(key_file_path, \"w\") as f:\n",
    "        f.write(os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "process_files(\n",
    "    txt_directory, output_text_directory, key_file_path, llm=\"Ollama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Query text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
