{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"articles\", ignore_errors=True)\n",
    "os.makedirs(\"articles/review\", exist_ok=True)\n",
    "\n",
    "from script.cropPage import *\n",
    "from script.textMining import *\n",
    "from script.textSegments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "ollama.pull(\"llama3\")\n",
    "ollama.pull(\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://vuir.vu.edu.au/43558/1/Ep43558.pdf\"\n",
    "\n",
    "# Extract filename and append '.pdf'\n",
    "filename = url.split(\"/\")[-1]\n",
    "\n",
    "# Full path where the file will be saved\n",
    "path = os.path.join(\"articles/review\", filename)\n",
    "\n",
    "# Send a GET request to the URL with headers\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "# Save the file if the request was successful\n",
    "assert response.status_code == 200, response.status_code\n",
    "\n",
    "with open(path, \"wb\") as f:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Crop page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing PDFs to process\n",
    "pdfsDirectory = \"articles/review\"\n",
    "pdfFiles = [\n",
    "    f\n",
    "    for f in os.listdir(pdfsDirectory)\n",
    "    if os.path.isfile(os.path.join(pdfsDirectory, f))\n",
    "]\n",
    "totalFiles = len(pdfFiles)\n",
    "\n",
    "# Output directory for cleaned text files\n",
    "outputDirectory = os.path.join(pdfsDirectory, \"\")\n",
    "\n",
    "# Crop all PDFs in the directory\n",
    "cropAllPdfs(pdfFiles, outputDirectory, totalFiles)\n",
    "\n",
    "# Test single PDF\n",
    "# pdfPath= \"review/1-s2.0-S0143416016300094-main.pdf\"\n",
    "# cropPDFMargins(pdfPath, outputDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Extract text\n",
    "\n",
    "Table not working yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing your text files\n",
    "text_files_directory = \"articles/output/textOutput\"\n",
    "\n",
    "# Directory containing PDFs to process\n",
    "pdfs_directory = \"articles/output\"\n",
    "\n",
    "# Output directory for cleaned text files\n",
    "output_directory = os.path.join(pdfs_directory, \"textOutput\")\n",
    "\n",
    "# Process all PDFs in the directory\n",
    "process_all_pdfs(pdfs_directory, output_directory)\n",
    "process_text_files(text_files_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Text segment\n",
    "\n",
    "Get embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of PDF file names\n",
    "txt_directory = \"articles/output/textOutput\"\n",
    "output_text_directory = \"text_output\"\n",
    "# Configure OpenAI API key\n",
    "key_file_path = \"api_key\"\n",
    "\n",
    "if \"OPENAI_API_KEY\" in os.environ:\n",
    "    with open(key_file_path, \"w\") as f:\n",
    "        f.write(os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "process_files(\n",
    "    txt_directory, output_text_directory, key_file_path, llm=\"Ollama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Query text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
